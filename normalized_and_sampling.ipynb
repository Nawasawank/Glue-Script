{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece627e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import FloatType, ArrayType\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67120c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"FraudDataNormalization\").getOrCreate()\n",
    "s3_path = \"s3://credit-transaction-fruad-new/data_cleaned.csv\"\n",
    "df = spark.read.csv(s3_path, header=True, inferSchema=True)\n",
    "\n",
    "exclude_cols = [\n",
    "    \"is_fraud\",\n",
    "    \"trans_time_is_night\", \"trans_date_is_weekend\",\n",
    "    \"category_entertainment\", \"category_food_dining\", \"category_gas_transport\",\n",
    "    \"category_grocery_net\", \"category_grocery_pos\", \"category_health_fitness\",\n",
    "    \"category_home\", \"category_kids_pets\", \"category_misc_net\", \"category_misc_pos\",\n",
    "    \"category_personal_care\", \"category_shopping_net\", \"category_shopping_pos\",\n",
    "    \"category_travel\"\n",
    "]\n",
    "\n",
    "numeric_cols = [c[0] for c in df.dtypes if c[1] in (\"int\", \"double\") and c[0] not in exclude_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ef424",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features_vector\")\n",
    "df_vector = assembler.transform(df)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features_vector\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "scaler_model = scaler.fit(df_vector)\n",
    "df_scaled = scaler_model.transform(df_vector)\n",
    "\n",
    "to_array_udf = udf(lambda v: v.toArray().tolist(), ArrayType(FloatType()))\n",
    "df_scaled = df_scaled.withColumn(\"scaled_array\", to_array_udf(col(\"scaled_features\")))\n",
    "\n",
    "for i, c in enumerate(numeric_cols):\n",
    "    df_scaled = df_scaled.withColumn(c, col(\"scaled_array\")[i])\n",
    "\n",
    "df_final = df_scaled.drop(\"features_vector\", \"scaled_features\", \"scaled_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bab1fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ Convert to pandas ------------------\n",
    "df_pd = df_final.toPandas()\n",
    "print(\"Data loaded & normalized. Shape:\", df_pd.shape)\n",
    "print(\"\\n[Original class distribution]\")\n",
    "print(df_pd[\"is_fraud\"].value_counts())\n",
    "\n",
    "# ------------------ Train-test split ------------------\n",
    "X = df_pd.drop(columns=[\"is_fraud\"])\n",
    "y = df_pd[\"is_fraud\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape : {X_test.shape}\")\n",
    "print(f\"y_test shape : {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250052b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\n[Class distribution after SMOTE on train set]\")\n",
    "print(y_train_res.value_counts())\n",
    "print(y_train_res.value_counts(normalize=True).round(4))\n",
    "\n",
    "# ------------------ Save datasets to S3 ------------------\n",
    "s3_output_prefix = \"s3://credit-transaction-fruad-new/processed/\"\n",
    "\n",
    "X_train_res.to_csv(s3_output_prefix + \"X_train_res.csv\", index=False)\n",
    "y_train_res.to_csv(s3_output_prefix + \"y_train_res.csv\", index=False)\n",
    "X_test.to_csv(s3_output_prefix + \"X_test.csv\", index=False)\n",
    "y_test.to_csv(s3_output_prefix + \"y_test.csv\", index=False)\n",
    "\n",
    "print(\"\\nAll datasets saved to S3 under:\", s3_output_prefix)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
